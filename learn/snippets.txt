# not for execution, but just code snippets

https://plotly.com/r/multiple-axes/ for plotly has great example

if you assign a variable as last operation, interpreter will print NOTHING
if you have a variable alone, interpreter will print it. This is why graph
will appear or not in ggplot

for ggplot, it creates a ggplot object, so you can add them together, but you
MUST use () around the addition
because pipe tightly binds to the final

# this doesn't work because "i" inside the data will be taken from the wrong context
for (i in range(1,2))
      x=x+  geom_line(aes(y = .data[[y_cols[i]]], color = y_cols[i]), linewidth = i)

1+2+3 > print()
will print 3, then 6

aes_string is used for plots to pass in the values
quote, unquote
substitute can be used for
c(a="1". b="7")

substitute(x <- c(x=1+a, b=2), list (a = 7))

> substitute(a <- x + 1, list(x = 1)) # must use the <-


but this is deprecated.

like you can't say  a= 1+3+3 %>% print()

you can only pipe together FUNCTIONS, not additions


plot_result <- function(df, mytitle, xlabel, ylabel, x_name, y_name, y2_name){
  line_plot <- ggplot(df, aes(x = x_name)) +
  geom_line(aes(y = y_name, color = y_name)) +
  geom_line(aes(y = y2_name, color = y2_name)) +
  labs(title = mytitle,
       x = xlabel,
       y = ylabel) +
  scale_color_manual(values = c(y_name = "blue", y2_name = "red"))

  print(line_plot)



RDS file is native format for file read/write

read/write xls spreadsheets
can creeate wb and add to them and write it outer()
https://janmarvin.github.io/openxlsx2/articles/openxlsx2_charts_manual.html

variable scoping: if function modifies a variable or it is an argument, it is local. If reads it only, it will read the global

life_expec <- life_expec %>%
  filter(Race == "All Races", Sex == "Both Sexes")

# vector with column headers

x=c(a="12", b="33")
> x
   a    b
"12" "33"

so now can use x["a"] or x[1] to get 12

df ... slice(-3)   # will remove just row #3
.... slice(-3:-5)  # will remove rows 3 thru 5
.... slice(-3,-5)  # will remove rows 3 and remove row 5
... slice(3,5)    # will include just these rows... so never mix positve and negatives in same call
... slice (2:n()) # will return 2 to the end


rm(var) to unbind a variable
Yes, the opposite of lag() is lead(). While lag() looks at previous values in a column, lead() looks at values that come after a specific row.

Here's an explanation of the default parameter in both lag() and lead():

result_tib <- tib %>%
  mutate(
    sum_shifted_columns = column1 + lag(column2, n = 3, default = 0)
  )

LAG pushes the column LOWER
LEAD pushes the column HIGHER.

In lag() and lead(), the default parameter specifies the value to be used when the requested lag/lead is not possible. For example, if you want to look back three rows using lag() or look forward three rows using lead() for the first few rows of a data frame, there won't be enough rows to satisfy the lag/lead. In such cases, the default value is used.

# change type of a column
# df  %>% mutate_at(vars(week), mdy)

# sort df by column week...
sorted_tib <- tib %>%
  arrange(date_column)

getwd()
setwd(path)

library(readxl) # to allow read

tibble
data types:
  https://tibble.tidyverse.org/articles/types.html

select() selects columns from data
filter() subsets rows of data
group_by() aggregates data
summarise() summarises data (calculating summary statistics)
arrange() sorts data
mutate() creates new variables

#tib$date_column <- as.Date(tib$date_column)



colnames(temp) <- c('year', 'month', str_replace_all(str_to_lower(s), ' ', '_'))

# Sample data frame
data <- data.frame(
  x = c(1, 2, 3, 4),
  y = c(5, 6, 7, 8)
)

# Using 'dplyr' to calculate the sum of columns 'x' and 'y'
# this will add a new column called sum_result (hence mutate) to the existing data structure computed
# from the existing columns. This is very powerful!!
# mutate will use first arg (piped df) as the context to eval the expression
data_with_sum <- data %>%
  mutate(sum_result = x + y)

# using with... it means evaluate "sum(x+y)" by taking x and y from the
# data frame column of that name (must be lowercase)
total_sum <- with(data, sum(x + y))
# this returns 36 but if we wanted the vector version with each element
vector_sum <- with(data, x + y)

poptotal <- poptotal %>%
        filter(year >= 2000) %>%
        #filter(year < 2015 | month <= 11) %>%
        with(ts(res_pop, start=c(2000,1), frequency = 12))
    #poptotal <- ts(select(filter(poptotal, year >= 2000), "res_pop"),
    #               start=c(2000,1),
    #               freqency=12)

    ## normalize gun sales by population
    totalSeasPop <- totalSeas / poptotal * 1000
    totalSeasScaled <- totalSeas / 280726

    ## create a new data frame that eventually stores all the
    ## data we need in the final piece
    out_data <- ts_to_dataframe(total, 'guns_total') %>%
        mutate(guns_total=round(guns_total, 3))

    ## expand the data.frame, adding more volumns
    out_data <- data.frame(out_data,
                           guns_total_seas=as.matrix(totalSeas),
                           guns_total_per_1000=round(as.matrix(totalSeasPop), digits=3),
                           guns_total_per_1000_scaled=round(as.matrix(totalSeasScaled), digits=3))
    if (debug) {
        print(head(out_data))
        print(tail(out_data))
    }

    ## create a temporary matrix for computing the
    ## handgun_share and longgun_share columns
    ## cbind works correctly here as it operates on timeseries object
    tmp <- cbind(final(seas(state_ts(alldata, 'Totals', 'handgun'))),
                 final(seas(state_ts(alldata, 'Totals', 'longgun'))),
                 final(seas(state_ts(alldata, 'Totals', 'other'))),
                 final(seas(state_ts(alldata, 'Totals', 'multiple_corrected'))))
    colnames(tmp) <- c('handgun', 'longgun', 'other', 'multiple')
    out_data <- data.frame(out_data, tmp)

    ## convert NAs to 0 in column other
    out_data$other[is.na(out_data$other)] <- 0

    ## compute the handgun/longgun share
    out_data <- within(out_data, {
        handgun_share=round(handgun / (handgun+longgun+other+multiple*0.5), 4)
        longgun_share=round(longgun / (handgun+longgun+other+multiple*0.5), 4)
        })

    ## plot percent of national for selected states
    show_states <- c('New Jersey', 'Maryland', 'Georgia',
                     'Louisiana', 'Mississippi', 'Missouri')

    for (s in show_states) {
        s.ts <- state_data(alldata, s, total, totalSeas)

        ## merge with out_data
        temp <- mutate(ts_to_dataframe(s.ts), value=round(value,3))
        colnames(temp) <- c('year', 'month', gsub(' ', '_', tolower(s)))
        out_data <- data.frame(out_data, temp[,3,drop=FALSE])
    }
    if (debug) {
        print(head(out_data))
        print(tail(out_data))
    }


 https://dplyr.tidyverse.org/reference/summarise.html

    Other single table verbs: arrange(), filter(), mutate(), reframe(), rename(), select(), slice()

Examples
# A summary applied to ungrouped tbl returns a single row
mtcars %>%
  summarise(mean = mean(disp), n = n())
#>       mean  n
#> 1 230.7219 32

# Usually, you'll want to group first
mtcars %>%
  group_by(cyl) %>%
  summarise(mean = mean(disp), n = n())
#> # A tibble: 3 × 3
#>     cyl  mean     n
#>   <dbl> <dbl> <int>
#> 1     4  105.    11
#> 2     6  183.     7
#> 3     8  353.    14

# Each summary call removes one grouping level (since that group
# is now just a single row)
mtcars %>%
  group_by(cyl, vs) %>%
  summarise(cyl_n = n()) %>%
  group_vars()
#> `summarise()` has grouped output by 'cyl'. You can override using the
#> `.groups` argument.
#> [1] "cyl"

# BEWARE: reusing variables may lead to unexpected results
mtcars %>%
  group_by(cyl) %>%
  summarise(disp = mean(disp), sd = sd(disp))
#> # A tibble: 3 × 3
#>     cyl  disp    sd
#>   <dbl> <dbl> <dbl>
#> 1     4  105.    NA
#> 2     6  183.    NA
#> 3     8  353.    NA

# Refer to column names stored as strings with the `.data` pronoun:
var <- "mass"
summarise(starwars, avg = mean(.data[[var]], na.rm = TRUE))
#> # A tibble: 1 × 1
#>     avg
#>   <dbl>
#> 1  97.3
# Learn more in ?rlang::args_data_masking

# In dplyr 1.1.0, returning multiple rows per group was deprecated in favor
# of `reframe()`, which never messages and always returns an ungrouped
# result:
mtcars %>%
   group_by(cyl) %>%
   summarise(qs = quantile(disp, c(0.25, 0.75)), prob = c(0.25, 0.75))
#> Warning: Returning more (or less) than 1 row per `summarise()` group was
#> deprecated in dplyr 1.1.0.
#> ℹ Please use `reframe()` instead.
#> ℹ When switching from `summarise()` to `reframe()`, remember that
#>   `reframe()` always returns an ungrouped data frame and adjust
#>   accordingly.
#> `summarise()` has grouped output by 'cyl'. You can override using the
#> `.groups` argument.
#> # A tibble: 6 × 3
#> # Groups:   cyl [3]
#>     cyl    qs  prob
#>   <dbl> <dbl> <dbl>
#> 1     4  78.8  0.25
#> 2     4 121.   0.75
#> 3     6 160    0.25
#> 4     6 196.   0.75
#> 5     8 302.   0.25
#> 6     8 390    0.75
# ->
mtcars %>%
   group_by(cyl) %>%
   reframe(qs = quantile(disp, c(0.25, 0.75)), prob = c(0.25, 0.75))
#> # A tibble: 6 × 3
#>     cyl    qs  prob
#>   <dbl> <dbl> <dbl>
#> 1     4  78.8  0.25
#> 2     4 121.   0.75
#> 3     6 160    0.25
#> 4     6 196.   0.75
#> 5     8 302.   0.25
#> 6     8 390    0.75
#>
#>
#>
#> library(ggplot2)

# Sample data
time <- c(1, 2, 3, 4, 5)
series1 <- c(10, 15, 12, 18, 20)
series2 <- c(8, 10, 14, 16, 22)

# Create a data frame
data <- data.frame(time, series1, series2)

# Create the line plot
line_plot <- ggplot(data, aes(x = time)) +
  geom_line(aes(y = series1, color = "Series 1")) +
  geom_line(aes(y = series2, color = "Series 2")) +
  labs(title = "Line Graph with Two Series",
       x = "Time",
       y = "Value") +
  scale_color_manual(values = c("Series 1" = "blue", "Series 2" = "red"))

print(line_plot)

plot_result <- function(df, mytitle, xlabel, ylabel, x_name, y_name, y2_name){

  # try with hard coded fields

  # the parens around the addition are important, because pipe tightly binds
  # so in a sum, it will sum the final element piped into print()

  myplot=df %>%  slice(2:n()) %>% (ggplot(aes(x = week, y = ncacm)) + # axes layer
  geom_line() + # geom layer
  labs(  # annotations layer
  title = "Non-COVID ACM per week")) %>% print()

  print("finished doing plot")
}


> a=c(week=df, month=df)
> View(a)
> class(a)
[1] "list"

# get right to the value using a static label
> a$week.ifr[3]
[1] 0.29
>

but better to use a list like this

dfs=list(week=df1, "month"=df2, year=df3) can use variable name for field names i think

dfs[["week"]] returns the week dataframe (instead of a list of length 1)
dfs$week      returns the same thing where week is a static name
so the two are equivalent

l=list()
l["new_item"]=df will stick df in the list with that inex


# Create a list with names for elements
my_list <- list(a = 1, b = 2)

# Change the name "a" to "bar"
my_list[["bar"]] <- my_list[["a"]]
my_list[["a"]] <- NULL

But easier just to use indexing to create the list:
l=list()
for (i in names)
  l[i]=df


 Create a sample dataframe
my_df <- data.frame(original_name = c(1, 2, 3), another_column = c("A", "B", "C"))

# Print the dataframe before renaming
print(my_df)

# Change the column name "original_name" to "new_name"
names(my_df)[names(my_df) == "original_name"] <- "new_name"

# Create some sample dataframes
df1 <- data.frame(x = 1:3, y = 4:6)
df2 <- data.frame(a = 7:9, b = 10:12)

# Specify the names as a vector
dataframe_names <- c("mydataframe1", "mydataframe2")

# Create an empty list
data_frame_collection <- list()

# Loop to populate the named list with dataframes
for (name in dataframe_names) {
  data_frame_collection[[name]] <- get(name)  # Retrieve the dataframe by its name
}

# Access the dataframes using their names
retrieved_df1 <- data_frame_collection$mydataframe1
retrieved_df2 <- data_frame_collection$mydataframe2

# Print the retrieved dataframes
print(retrieved_df1)
print(retrieved_df2)

x=c(1,3,4) are 3 values just like seq(1,3)
y=list(1,2,3) is a single value

if named values then

ATOMIC VECTORS
x=c(a=32, b=23)
x[["a"]] will always return the value in that position
x["a"] will return a named value

LISTS
y["a"] will return a list of named objects
y[["a"]] will return contents of the slot
y$a will return contents of the named  slot if y is a list
but x$a returns an error



# Skip the first 5 rows using the pipe operator
result <- df %>%
  slice(6:n())  # range of rows to select

head tail also work. can use - value for the complement so
head(5) is first 5 rows and head(-5) is all but first 5 rows

# Create a list of dataframes with corresponding sheet names
dataframe_list <- list(sheeta = data.frame(x = 1:3, y = 4:6),
                        sheetb = data.frame(a = 7:9, b = 10:12))


PIPE

If you pipe in a concat, it calls the function with those arguments in the concat
and returns the concat of the results

if you pipe in a list, it treats it as ONE object.

f=function(a,b=1,c=2) a+1
c(6,343,343,343,345) %>% f()
[1] "612"   "34312" "34312" "34312" "34512"
>

solving the expects a hard symbol instead of a variable problem

df <- data.frame(group_col = c("A", "B", "A", "B"),
                 value = c(10, 20, 30, 40))

# Variable containing the field name
field_name <- "group_col"

# Convert variable to a symbol using sym()
field_symbol <- sym(field_name)

# Use !! to evaluate the variable as a column name in group_by
grouped_df <- df %>%
  group_by(!!field_symbol) %>%
  summarize(total = sum(value))

# Print the grouped dataframe
print(grouped_df)

calc_stats <- function (df, key_row_df){
  # input has week, cases, deaths columns
  # add 4 new computed columns: ncacm, ifr, dead:alive odds, and derivatives
  # key_row_df has the elements we need to compute the stats and is passed in
    df %>% mutate(ncacm = acm-deaths) %>%
         mutate(ifr = deaths/cases) %>%
         mutate(odds = deaths/(cases-deaths)) %>%
         mutate(odds_ratio=odds/lag(odds, n=8, default=0)) %>%
         mutate(ifr8 =   ifr - lag(ifr, n=8, default=0)) %>%
         mutate(odds8 = odds - lag(odds, n=8, default=0)) # change in odds


wb=wb_workbook()
wb$add_worksheet("steve")
wb$add_data(x=df)
wb$save(filename
)
wb$add_data(x=df) (to add in table format
wb$remove_worksheet()

wb$save("mtcars.xlsx")


         mutate(odds_ratio=odds/lag(odds, n=8, default=0)) %>%
         mutate(ifr8 =   ifr - lag(ifr, n=8, default=0)) %>%
         mutate(odds8 = odds - lag(odds, n=8, default=0)) # change in odds

df$week will refer to column content... if one row, returns a sequence of values (like c() does)

  myplot=ggplot(df, aes(x = .data[[x_col]]))+
    scale_color_manual(values = c("blue", "red"))+      # ,"green","orange","magenta"))
    # now we can add a line plot for each y_col sent in
  for (i in seq(1,length(y_cols))){
    myplot=myplot+geom_line(aes(y = .data[[y_cols[i]]], color = y_cols[i]), linewidth = 1)
  }
  myplot=myplot+
        labs(title = mytitle,
         x = x_col,
         y = ytitle,
         color = "Legend") +
    # scale_x_continuous(breaks = seq(min(.data[[x_col]]), max(.data[[x_col]]), by = 1)) +
    scale_x_continuous(n.breaks=10, minor_breaks=seq(1,30)) +

  theme_minimal()
  print(myplot)


https://cran.r-project.org/web/packages/r2r/vignettes/r2r.html

# Install and load the r2r package
# install.packages("r2r")
library(r2r)

# Create a hashmap: always use [[ ]] !!

my_hashmap[["foo"]]="barf"
my_hashmap[["foo"]] to referernce it

# Get a list of keys
k <- keys(my_hashmap)

# Print the list of keys
print(keys)
delete(hashmap, "a")

length(m) is number of keys


k[[1]] is the first key... you can iterate on this that is a named list

  for (sheet_name in names(dataframe_list)) {





  # %>% head(520) #  %>%  limit number of records for debug
  # filter_out_bad_actors()  %>%
  # add filter on state here if wanted to limit everything below, e.g., calif
  #    filter_select(state, c('CA')


  # %>% head(520) #  %>%  limit number of records for debug
  # filter_out_bad_actors()  %>%
  # add filter on state here if wanted to limit everything below, e.g., calif
  #    filter_select(state, c('CA')


provider_nums_to_remove= c(102, 104)  # concatenation of providers to remove
filter_out_bad_actors <- function(df){
  df # nothing to filter so far. use below line if find a bogus provider
  # filter out records at start based on provider number
    # df %>% filter(!provider_num %in% provider_nums_to_remove)
}

# remove facilities with bogus counts (if we can find any)

# only keep the records of a df where the col, value is a match, e.g.,
# provider_state, seq("CA", "OR")
filter_select <- function(df, col, val){
  df %>% filter(col %in% val)
}


 table2$ProviderNumber
[1] 3 5
> xx="ProviderNumber"
> table2$xx
NULL
> table2[[xx]]
[1] 3 5

so can hard code or use [[abc]]


In most cases, when you want to perform an element-wise logical AND operation on vectors, you should use the & operator. If you need to evaluate multiple conditions sequentially and short-circuit the evaluation, you can use the && operator.

string substitute from first x to an a
for looking for ., must quote it since first is a regular expression
> sub("x","a","xxxaxxx")
[1] "axxaxxx"
>

terminate iteration of for loop
    if (sheet_name==master) next  # don't write out master spreadsheet







  # Loop over the list and add each dataframe to a separate worksheet
  # if the dataframes in the list don't have a name, nothing will be written
  # so pass in list(sheet1=df1, mysheet2=df2)
  # if the dataframes list is empty, you'll get a warning about no worksheets

  for (sheet_name in columns_of_interest) {
    # create empty sheet with given name
  }
  # Save the workbook to the specified output file
  file_suffix=dict[[state_name]]  # get the state
  if (is.null(file_suffix))
    # it's the first run so save as specified name
    output_filename=output_file
  else
    # append _CA if calif

        output_filename=sub("\\.", paste0("_", file_suffix,"."),output_file)


  dict # return the dict for others to process
}



OR_analysis_key="or_analysis"   # hashmap key name for summary analysis stored in ALL

OR_analysis=function(){
  # replace with new fcn
  # make a dataframe of the state and the log of the OR value averaged over Feb (rows ) (geometric mean) for each state
  # Empty vectors to store results
  state_names <- character()
  odds_ref_values <- numeric()
  odds_values <- numeric()
  OR_values <- numeric()

  # Iterate over state hashmaps
  for (key in keys(root)) { # iterate over the states
    state=root[[key]]   # get the hashmap for the state
    state_name <- state[[name]]
    week_df <- state[[week]]

    cases = sum(week_df$cases[38:40])    # take infections from earlier
    deaths = sum(week_df$deaths[39:41])  # months of feb

    ref_cases =sum(week_df$cases[27:29])
    ref_deaths = sum(week_df$deaths[28:30])

    odds=deaths/(cases-deaths)
    odds_reference = ref_deaths/(ref_cases-ref_deaths)
    odds_ratio=odds/odds_reference

    state_names <- append(state_names, state_name)
    odds_values <- append(odds_values, odds)
    odds_ref_values <- append(odds_ref_values, odds_reference)
    OR_values <- append(OR_values, odds_ratio)
  }

  print(state_names)
  print(odds_values)
  print(odds_ref_values)
  print(OR_values)

  # Create a new dataframe
  result_df <- data.frame(
    State = state_names,
    odds = odds_values,
    odds_ref = odds_ref_values,
    odds_ratio = OR_values
  )

  # save it in root under ALL
  root[[ALL]][[OR_analysis_key]]=result_df
}
